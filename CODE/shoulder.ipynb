{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"shoulder.ipynb","version":"0.3.2","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"PMUB88gy9g7o","colab_type":"code","colab":{},"outputId":"e4120983-a133-42af-fc22-4b969afc05c3"},"source":["import sys \n","!{sys.executable} -m pip install tensorflow"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow in c:\\programdata\\anaconda3\\lib\\site-packages (1.13.1)\n","Requirement already satisfied: gast>=0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.2)\n","Requirement already satisfied: grpcio>=1.8.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.1)\n","Requirement already satisfied: absl-py>=0.1.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.7.1)\n","Requirement already satisfied: astor>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.8.0)\n","Requirement already satisfied: numpy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: six>=1.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.0)\n","Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.13.1)\n","Requirement already satisfied: wheel>=0.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.32.3)\n","Requirement already satisfied: protobuf>=3.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.8)\n","Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.13.0)\n","Requirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.14.1)\n","Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.1.1)\n","Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow) (40.6.3)\n","Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n","Requirement already satisfied: mock>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (3.0.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YR00g-IQ9g7w","colab_type":"code","colab":{},"outputId":"ecc0c687-f641-402c-ad5f-1ac654bfac95"},"source":["import sys \n","!{sys.executable} -m pip install opencv-python\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: opencv-python in c:\\programdata\\anaconda3\\lib\\site-packages (4.1.0.25)\n","Requirement already satisfied: numpy>=1.14.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from opencv-python) (1.16.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6ZKmtORc9g70","colab_type":"code","colab":{},"outputId":"4b47861d-0ae2-4ad0-b807-e79119233207"},"source":["import os\n","import numpy as np\n","import cv2\n","import keras.backend as K\n","import random\n","import tensorflow as tf\n","\n","\n","def load_image(Path = './valid/XR_SHOULDER', size = 512):\n","    Images = []\n","    for path in Path:\n","        try:\n","            image = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n","            image = cv2.resize(image,(size,size))\n","            Images.append(image)\n","\n","        except Exception as e:\n","            print(str(e))\n","\n","    Images = np.asarray(Images).astype('float32')\n","    Images=Images.reshape((len(Path),size,size,1))\n","\n","    mean = np.mean(Images)\t\t\t#normalization\n","    std = np.std(Images)\n","    Images = (Images - mean) / std\n","    return Images"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"q7suREYm9g73","colab_type":"code","colab":{},"outputId":"8cb6b3ac-75db-4610-9896-758a1539f578"},"source":["def load_path(root_path = './valid/XR_SHOULDER', size = 512):\n","\t'''\n","\tload MURA dataset\n","\t'''\n","\n","\tPath = []\n","\tlabels = []\n","\tfor root,dirs,files in os.walk(root_path): #Read all pictures, os.walk Return to iterator genertor Traverse all files\n","\t\tfor name in files:\n","\t\t\tpath_1 = os.path.join(root,name)\n","\t\t\tPath.append(path_1)\n","\t\t\tif root.split('_')[-1]=='positive':\t #positive Label is 1，otherwise 0；\n","\t\t\t\tlabels+=[1]   \t          \t #Last level directory file patient11880\\\\study1_negative\\\\image3.png\n","\t\t\telse:\n","\t\t\t    labels+=[0]\n","\tprint (len(Path))\n","\tlabels = np.asarray(labels)\n","\treturn Path, labels\n","\n","\n","Path,labels=load_path(r'/content/MURA-v1.1/train/XR_SHOULDER',64)\n","images=load_image(Path,64)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["8379\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hY2IqENb9g76","colab_type":"code","colab":{}},"source":["     def train_model():\n","        model=tf.keras.Sequential([\n","        tf.keras.layers.Conv2D(64,(3,3),padding='same',activation=tf.nn.relu,input_shape=(64,64,1)),\n","        tf.keras.layers.MaxPool2D((2,2),strides=1),\n","        tf.keras.layers.Dropout(0.25),\n","        tf.keras.layers.Conv2D(128,(3,3),padding='same',activation=tf.nn.relu),\n","        tf.keras.layers.MaxPool2D((2,2),strides=2,padding='same'),\n","        tf.keras.layers.Dropout(0.25),\n","        tf.keras.layers.Conv2D(64,(3,3),padding='same',activation=tf.nn.relu),\n","        tf.keras.layers.MaxPool2D((2,2),strides=1),\n","        tf.keras.layers.Dropout(0.25),       \n","        tf.keras.layers.Conv2D(64,(3,3),padding='same',activation=tf.nn.relu),\n","        tf.keras.layers.MaxPool2D((2,2),strides=2,padding='same'),\n","        tf.keras.layers.Dropout(0.25),\n","        tf.keras.layers.Conv2D(32,(3,3),padding='same',activation=tf.nn.relu),\n","        tf.keras.layers.MaxPool2D((2,2),strides=1),\n","        tf.keras.layers.Dropout(0.25),\n","        tf.keras.layers.Flatten(),\n","        tf.keras.layers.Dense(128,activation=tf.nn.relu),\n","        tf.keras.layers.Dropout(0.25),\n","        tf.keras.layers.Dense(2,activation=tf.nn.softmax)\n","        ])\n","        model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n","    \n","        model.fit(images,labels,epochs=40,verbose=2)\n","     \n","        return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"W6KVViGH9g78","colab_type":"code","colab":{},"outputId":"6526b113-49cf-46d6-e6eb-3385ca7a4e12"},"source":["model=train_model()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/40\n"," - 9s - loss: 0.6918 - acc: 0.5435\n","Epoch 2/40\n"," - 8s - loss: 0.6613 - acc: 0.6071\n","Epoch 3/40\n"," - 8s - loss: 0.6350 - acc: 0.6432\n","Epoch 4/40\n"," - 9s - loss: 0.6093 - acc: 0.6674\n","Epoch 5/40\n"," - 9s - loss: 0.5958 - acc: 0.6778\n","Epoch 6/40\n"," - 8s - loss: 0.5725 - acc: 0.7031\n","Epoch 7/40\n"," - 9s - loss: 0.5499 - acc: 0.7203\n","Epoch 8/40\n"," - 8s - loss: 0.5298 - acc: 0.7336\n","Epoch 9/40\n"," - 8s - loss: 0.5071 - acc: 0.7508\n","Epoch 10/40\n"," - 8s - loss: 0.4813 - acc: 0.7667\n","Epoch 11/40\n"," - 8s - loss: 0.4619 - acc: 0.7735\n","Epoch 12/40\n"," - 9s - loss: 0.4381 - acc: 0.7966\n","Epoch 13/40\n"," - 9s - loss: 0.4192 - acc: 0.8020\n","Epoch 14/40\n"," - 9s - loss: 0.3840 - acc: 0.8259\n","Epoch 15/40\n"," - 8s - loss: 0.3612 - acc: 0.8369\n","Epoch 16/40\n"," - 9s - loss: 0.3405 - acc: 0.8505\n","Epoch 17/40\n"," - 9s - loss: 0.3184 - acc: 0.8588\n","Epoch 18/40\n"," - 10s - loss: 0.2984 - acc: 0.8715\n","Epoch 19/40\n"," - 10s - loss: 0.2799 - acc: 0.8801\n","Epoch 20/40\n"," - 9s - loss: 0.2583 - acc: 0.8885\n","Epoch 21/40\n"," - 9s - loss: 0.2383 - acc: 0.8981\n","Epoch 22/40\n"," - 9s - loss: 0.2203 - acc: 0.9073\n","Epoch 23/40\n"," - 10s - loss: 0.2136 - acc: 0.9114\n","Epoch 24/40\n"," - 9s - loss: 0.1902 - acc: 0.9240\n","Epoch 25/40\n"," - 8s - loss: 0.1837 - acc: 0.9235\n","Epoch 26/40\n"," - 9s - loss: 0.1762 - acc: 0.9319\n","Epoch 27/40\n"," - 8s - loss: 0.1652 - acc: 0.9354\n","Epoch 28/40\n"," - 8s - loss: 0.1593 - acc: 0.9356\n","Epoch 29/40\n"," - 8s - loss: 0.1511 - acc: 0.9420\n","Epoch 30/40\n"," - 8s - loss: 0.1444 - acc: 0.9441\n","Epoch 31/40\n"," - 8s - loss: 0.1381 - acc: 0.9453\n","Epoch 32/40\n"," - 9s - loss: 0.1229 - acc: 0.9532\n","Epoch 33/40\n"," - 8s - loss: 0.1263 - acc: 0.9524\n","Epoch 34/40\n"," - 8s - loss: 0.1247 - acc: 0.9538\n","Epoch 35/40\n"," - 8s - loss: 0.1112 - acc: 0.9587\n","Epoch 36/40\n"," - 8s - loss: 0.1030 - acc: 0.9615\n","Epoch 37/40\n"," - 8s - loss: 0.1095 - acc: 0.9611\n","Epoch 38/40\n"," - 8s - loss: 0.1015 - acc: 0.9628\n","Epoch 39/40\n"," - 8s - loss: 0.0992 - acc: 0.9620\n","Epoch 40/40\n"," - 8s - loss: 0.1000 - acc: 0.9646\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zDrjsSaD9g7_","colab_type":"code","colab":{},"outputId":"42a3d5e1-5d97-4dac-b9cc-415303f3dbde"},"source":["model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_4 (Conv2D)            (None, 28, 28, 32)        320       \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 14, 14, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 3136)              0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 128)               401536    \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 2)                 258       \n","=================================================================\n","Total params: 420,610\n","Trainable params: 420,610\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N7KAntkg9g8D","colab_type":"code","colab":{},"outputId":"f93c681d-98d1-463d-9701-b46c6981a3e1"},"source":["#Validation of test data\n","ValidPath,Validlabels=load_path(r'/content/MURA-v1.1/valid/XR_SHOULDER',64)\n","Validimages=load_image(ValidPath,64)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["563\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OAIwvl8w9g8G","colab_type":"code","colab":{},"outputId":"f0534478-b3d8-466a-b01a-0c89d73b44fe"},"source":["score = model.evaluate(Validimages, Validlabels, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test loss: 1.4193648698063135\n","Test accuracy: 0.660746\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lf_JrW9G9g8J","colab_type":"code","colab":{}},"source":["model.save('shoulder.h5')"],"execution_count":0,"outputs":[]}]}