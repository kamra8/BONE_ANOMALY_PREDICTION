{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\programdata\\anaconda3\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.1)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.8.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.13.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.32.3)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow) (40.6.3)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
      "Requirement already satisfied: mock>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (3.0.5)\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "!{sys.executable} -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\programdata\\anaconda3\\lib\\site-packages (4.1.0.25)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from opencv-python) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "!{sys.executable} -m pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import keras.backend as K\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def load_image(Path = './valid/XR_SHOULDER', size = 512):\n",
    "    Images = []\n",
    "    for path in Path:\n",
    "        try:\n",
    "            image = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image,(size,size))\n",
    "            Images.append(image)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "\n",
    "    Images = np.asarray(Images).astype('float32')\n",
    "    Images=Images.reshape((len(Path),28,28,1))\n",
    "\n",
    "    mean = np.mean(Images)\t\t\t#normalization\n",
    "    std = np.std(Images)\n",
    "    Images = (Images - mean) / std\n",
    "    return Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8379\n"
     ]
    }
   ],
   "source": [
    "def load_path(root_path = './valid/XR_SHOULDER', size = 512):\n",
    "\t'''\n",
    "\tload MURA dataset\n",
    "\t'''\n",
    "\n",
    "\tPath = []\n",
    "\tlabels = []\n",
    "\tfor root,dirs,files in os.walk(root_path): #Read all pictures, os.walk Return to iterator genertor Traverse all files\n",
    "\t\tfor name in files:\n",
    "\t\t\tpath_1 = os.path.join(root,name)\n",
    "\t\t\tPath.append(path_1)\n",
    "\t\t\tif root.split('_')[-1]=='positive':\t #positive Label is 1，otherwise 0；\n",
    "\t\t\t\tlabels+=[1]   \t          \t #Last level directory file patient11880\\\\study1_negative\\\\image3.png\n",
    "\t\t\telse:\n",
    "\t\t\t    labels+=[0]\n",
    "\tprint (len(Path))\n",
    "\tlabels = np.asarray(labels)\n",
    "\treturn Path, labels\n",
    "\n",
    "\n",
    "Path,labels=load_path(r'F:\\Bone Fracture Data\\MURA-v1.1\\train\\XR_SHOULDER',64)\n",
    "images=load_image(Path,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "     def train_model():\n",
    "        model=tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(64,(3,3),padding='same',activation=tf.nn.relu,input_shape=(64,64,1)),\n",
    "        tf.keras.layers.MaxPool2D((2,2),strides=1),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Conv2D(128,(3,3),padding='same',activation=tf.nn.relu),\n",
    "        tf.keras.layers.MaxPool2D((2,2),strides=2,padding='same'),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Conv2D(64,(3,3),padding='same',activation=tf.nn.relu),\n",
    "        tf.keras.layers.MaxPool2D((2,2),strides=1),#no padding strides is one\n",
    "        tf.keras.layers.Dropout(0.25),       \n",
    "        tf.keras.layers.Conv2D(64,(3,3),padding='same',activation=tf.nn.relu),\n",
    "        tf.keras.layers.MaxPool2D((2,2),strides=2,padding='same'),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128,activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        tf.keras.layers.Dense(6,activation=tf.nn.softmax)\n",
    "        ])\n",
    "        model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "        model.fit(Images,labels,epochs=30,verbose=2)\n",
    "     \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      " - 9s - loss: 0.6918 - acc: 0.5435\n",
      "Epoch 2/40\n",
      " - 8s - loss: 0.6613 - acc: 0.6071\n",
      "Epoch 3/40\n",
      " - 8s - loss: 0.6350 - acc: 0.6432\n",
      "Epoch 4/40\n",
      " - 9s - loss: 0.6093 - acc: 0.6674\n",
      "Epoch 5/40\n",
      " - 9s - loss: 0.5958 - acc: 0.6778\n",
      "Epoch 6/40\n",
      " - 8s - loss: 0.5725 - acc: 0.7031\n",
      "Epoch 7/40\n",
      " - 9s - loss: 0.5499 - acc: 0.7203\n",
      "Epoch 8/40\n",
      " - 8s - loss: 0.5298 - acc: 0.7336\n",
      "Epoch 9/40\n",
      " - 8s - loss: 0.5071 - acc: 0.7508\n",
      "Epoch 10/40\n",
      " - 8s - loss: 0.4813 - acc: 0.7667\n",
      "Epoch 11/40\n",
      " - 8s - loss: 0.4619 - acc: 0.7735\n",
      "Epoch 12/40\n",
      " - 9s - loss: 0.4381 - acc: 0.7966\n",
      "Epoch 13/40\n",
      " - 9s - loss: 0.4192 - acc: 0.8020\n",
      "Epoch 14/40\n",
      " - 9s - loss: 0.3840 - acc: 0.8259\n",
      "Epoch 15/40\n",
      " - 8s - loss: 0.3612 - acc: 0.8369\n",
      "Epoch 16/40\n",
      " - 9s - loss: 0.3405 - acc: 0.8505\n",
      "Epoch 17/40\n",
      " - 9s - loss: 0.3184 - acc: 0.8588\n",
      "Epoch 18/40\n",
      " - 10s - loss: 0.2984 - acc: 0.8715\n",
      "Epoch 19/40\n",
      " - 10s - loss: 0.2799 - acc: 0.8801\n",
      "Epoch 20/40\n",
      " - 9s - loss: 0.2583 - acc: 0.8885\n",
      "Epoch 21/40\n",
      " - 9s - loss: 0.2383 - acc: 0.8981\n",
      "Epoch 22/40\n",
      " - 9s - loss: 0.2203 - acc: 0.9073\n",
      "Epoch 23/40\n",
      " - 10s - loss: 0.2136 - acc: 0.9114\n",
      "Epoch 24/40\n",
      " - 9s - loss: 0.1902 - acc: 0.9240\n",
      "Epoch 25/40\n",
      " - 8s - loss: 0.1837 - acc: 0.9235\n",
      "Epoch 26/40\n",
      " - 9s - loss: 0.1762 - acc: 0.9319\n",
      "Epoch 27/40\n",
      " - 8s - loss: 0.1652 - acc: 0.9354\n",
      "Epoch 28/40\n",
      " - 8s - loss: 0.1593 - acc: 0.9356\n",
      "Epoch 29/40\n",
      " - 8s - loss: 0.1511 - acc: 0.9420\n",
      "Epoch 30/40\n",
      " - 8s - loss: 0.1444 - acc: 0.9441\n",
      "Epoch 31/40\n",
      " - 8s - loss: 0.1381 - acc: 0.9453\n",
      "Epoch 32/40\n",
      " - 9s - loss: 0.1229 - acc: 0.9532\n",
      "Epoch 33/40\n",
      " - 8s - loss: 0.1263 - acc: 0.9524\n",
      "Epoch 34/40\n",
      " - 8s - loss: 0.1247 - acc: 0.9538\n",
      "Epoch 35/40\n",
      " - 8s - loss: 0.1112 - acc: 0.9587\n",
      "Epoch 36/40\n",
      " - 8s - loss: 0.1030 - acc: 0.9615\n",
      "Epoch 37/40\n",
      " - 8s - loss: 0.1095 - acc: 0.9611\n",
      "Epoch 38/40\n",
      " - 8s - loss: 0.1015 - acc: 0.9628\n",
      "Epoch 39/40\n",
      " - 8s - loss: 0.0992 - acc: 0.9620\n",
      "Epoch 40/40\n",
      " - 8s - loss: 0.1000 - acc: 0.9646\n"
     ]
    }
   ],
   "source": [
    "model=trainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               401536    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 420,610\n",
      "Trainable params: 420,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563\n"
     ]
    }
   ],
   "source": [
    "#Validation of test data\n",
    "ValidPath,Validlabels=load_path(r'F:\\Bone Fracture Data\\MURA-v1.1\\valid\\XR_SHOULDER',64)\n",
    "Validimages=load_image(ValidPath,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.4193648698063135\n",
      "Test accuracy: 0.660746\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(Validimages, Validlabels, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('shoulder.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
